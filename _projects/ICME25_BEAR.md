---
layout: page
title: BEAR
description: BEAR: A Video Dataset For Fine-grained Behaviors Recognition Oriented with Action and Environment Factors (ICME-2025)
importance: 1
category: research
---

Comming Soon!

<!-- 
<h3 align="center">BEAR: A Video Dataset For Fine-grained Behaviors Recognition Oriented with Action and Environment Factors</h3>

  <p align="center">
    Chengyang Hu<sup>1</sup>, Yuduo Chen<sup>2</sup>, Lizhuang Ma<sup>1</sup>
    <br />
    <sup>1</sup> Shanghai Jiao Tong University
    <br />
    <a><strong>(ICME2025)</strong></a>
    <br />
    <br />
    <a href="https://ojs.aaai.org/index.php/AAAI/article/view/27992">Paper</a>
    ·
    <a href="https://github.com/hu-cheng-yang/CVPR2024-HPDR?tab=readme-ov-file">Code</a>
    <!-- Code (Release Soon) -->
    ·
    <a href="https://hu-cheng-yang.github.io/projects/ICME25_BEAR">Project Page</a>

  </p>

## Abstract

Behavior recognition is an important task in video representation learning. An essential aspect pertains to effective feature learning conducive to behavior recognition. Recently, researchers have started to study fine-grained behavior recognition, which provides similar behaviors and encourages the model to concern with more details of behaviors with effective features for distinction. However, previous fine-grained behaviors limited themselves to controlling partial information to be similar, leading to an unfair and not comprehensive evaluation of existing works. In this work, we develop a new video fine-grained behavior dataset, named BEAR, which provides fine-grained (i.e. similar) behaviors that uniquely focus on two primary factors defining behavior: Environment and Action. It includes two fine-grained behavior protocols including Fine-grained Behavior with Similar Environments and Fine-grained Behavior with Similar Actions as well as multiple sub-protocols as different scenarios. Furthermore, with this new dataset, we conduct multiple experiments with different behavior recognition models. Our research primarily explores the impact of input modality, a critical element in studying the environmental and action-based aspects of behavior recognition. Our experimental results yield intriguing insights that have substantial implications for further research endeavors.

## Data Access

We will release the dataset and protocols as soon as possible.


<!-- CONTRIBUTING -->
## Citing Our Work

If you find our work is useful in your reasearch, please consider citing:
```bib
@inproceedings{hu2024domain,
  title={Domain-Hallucinated Updating for Multi-Domain Face Anti-spoofing},
  author={Hu, Chengyang and Zhang, Ke-Yue and Yao, Taiping and Liu, Shice and Ding, Shouhong and Tan, Xin and Ma, Lizhuang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={3},
  pages={2193--2201},
  year={2024}
}
```


<!-- ACKNOWLEDGMENTS -->
## Acknowledgments
Our work is based on the following opensource project. We thank their authors for making the source code publically available.
* [mmaction](https://github.com/open-mmlab/mmaction2) -->

